{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176f4714",
   "metadata": {},
   "source": [
    "# Transformer Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2def0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload of local Python modules (e.g., models)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5001b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import time\n",
    "\n",
    "# save checkpoints using orbax\n",
    "from pathlib import Path\n",
    "\n",
    "# local imports\n",
    "import models.models as models\n",
    "import utils.generation as generation\n",
    "import utils.eval as eval\n",
    "\n",
    "# utilities\n",
    "# Import our new utilities\n",
    "from utils import (\n",
    "    load_config,\n",
    "    print_config,\n",
    "    plot_training_curves,\n",
    "    analyze_training_performance,\n",
    "    save_collected_checkpoints,\n",
    "    logger,\n",
    "    test_checkpoint,\n",
    "    load_checkpoint,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463761a4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86825275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ./data/text8_train.txt and ./data/text8_test.txt files\n",
    "with open(\"./data/text8_train.txt\", \"r\") as f:\n",
    "    train_text_full = f.read()\n",
    "with open(\"./data/text8_test.txt\", \"r\") as f:\n",
    "    test_text = f.read()\n",
    "\n",
    "train_ratio = 0.95\n",
    "N = len(train_text_full)\n",
    "cut = int(N * train_ratio)\n",
    "\n",
    "train_text = train_text_full[:cut]  # training text\n",
    "val_text = train_text_full[cut:]  # validation text\n",
    "# print the length of the training text and test text\n",
    "print(f\"Length of training text: {len(train_text):_} characters\")\n",
    "print(f\"Length of validation text: {len(val_text):_} characters\")\n",
    "print(f\"Length of test text: {len(test_text):_} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary (lowercase + space + a few punctuations)\n",
    "char_set = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
    "char_to_int = {ch:i for i,ch in enumerate(char_set)}\n",
    "int_to_char = {i:ch for ch,i in char_to_int.items()}\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    \"\"\"Encode string to array of integers\"\"\"\n",
    "    ids = [char_to_int[c] for c in s]\n",
    "    return np.array(ids, dtype=np.uint8)  # use np.uint8 to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the text\n",
    "train_text_int = encode(train_text)\n",
    "val_text_int = encode(val_text)\n",
    "test_text_int = encode(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: display a few random characters from the training text\n",
    "T = 128\n",
    "for _ in range(5):\n",
    "    # choose random position in text\n",
    "    N = np.random.randint(low=0, high=len(train_text)-T)\n",
    "    print(train_text[N:N+T])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a1c8f",
   "metadata": {},
   "source": [
    "## Load Conifguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301190ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"./configs/baseline.yaml\"\n",
    "# Load configuration\n",
    "config = load_config(CONFIG_PATH)\n",
    "print_config(config)\n",
    "\n",
    "# Initialize random seed\n",
    "key = jax.random.key(config.training.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724c34b",
   "metadata": {},
   "source": [
    "# Create a basic Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5955c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, config):\n",
    "    # create a basic Transformer model\n",
    "    model = models.DecoderOnlyTransformer(\n",
    "        vocab_size=config.model.vocab_size,\n",
    "        d_model=config.model.d_model,\n",
    "        n_layers=config.model.n_layers,\n",
    "        n_heads=config.model.n_heads,\n",
    "        max_len=config.model.max_len,\n",
    "        mlp_ratio=config.model.mlp_ratio,\n",
    "        emb_dropout=config.model.emb_dropout,\n",
    "        mlp_dropout=config.model.mlp_dropout,\n",
    "        attn_dropout=config.model.attn_dropout,\n",
    "        resid_dropout=config.model.resid_dropout\n",
    "    )\n",
    "    # create a dummy input for initialization\n",
    "    dummy = jnp.zeros((1, min(16, config.model.max_len)), dtype=jnp.int32)\n",
    "    # pass the dummy input to the model to initialize the parameters\n",
    "    params = model.init({\"params\": rng}, dummy, deterministic=True)[\"params\"]\n",
    "    return model, params\n",
    "\n",
    "\n",
    "def count_params(params):\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params = create_train_state(key, config)\n",
    "num_params = count_params(params)\n",
    "print(f\"Model created: {config.model_name}\")\n",
    "print(f\"Number of parameters: {num_params:_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52231d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: create a batch of data & run a forward pass\n",
    "B, T = 4, 32\n",
    "batch = jax.random.randint(\n",
    "    key=key,\n",
    "    shape=(B, T), minval=0, maxval=len(char_set))\n",
    "logits = model.apply({\"params\": params}, batch, deterministic=True)\n",
    "\n",
    "print(\"batch shape:\", batch.shape)  # (B, T)\n",
    "print(\"logits shape:\", logits.shape)  # (B, T, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0213425",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_and_metrics(logits, targets):\n",
    "\n",
    "    B, T, V = logits.shape\n",
    "\n",
    "    # position weights mode\n",
    "    # linear: w(t) = 0.3 + 0.7 * (t / T)\n",
    "    # sqrt: w(t) = 0.1 + 0.9 * sqrt(t / T)\n",
    "    # none: w(t) = 1.0\n",
    "    tail_scheme = \"linear\"\n",
    "\n",
    "    if config.loss.LABEL_SMOOTHING and config.loss.ls_eps > 0.0:\n",
    "        tgt = jax.nn.one_hot(targets, V)\n",
    "        tgt = (1.0 - config.loss.ls_eps) * tgt + (config.loss.ls_eps / V)\n",
    "        per_pos_ce = optax.softmax_cross_entropy(logits, tgt)\n",
    "    else:\n",
    "        per_pos_ce = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits.reshape(-1, V), targets.reshape(-1)\n",
    "        ).reshape(B, T)\n",
    "\n",
    "    # Position weights: emphasize later positions, but don't discard early ones\n",
    "    if tail_scheme == \"linear\":\n",
    "        w = jnp.linspace(0.3, 1.0, T)\n",
    "    elif tail_scheme == \"sqrt\":\n",
    "        w = 0.1 + 0.9 * jnp.sqrt(jnp.linspace(0.0, 1.0, T))\n",
    "    else:\n",
    "        w = jnp.ones((T,))\n",
    "    w = w[None, :]\n",
    "\n",
    "    # Weighted loss\n",
    "    loss_weighted = (per_pos_ce * w).sum() / (B * w.sum())\n",
    "\n",
    "    # Entropy bonus to encourage less-peaked distributions\n",
    "    if config.loss.entropy_lambda > 0.0:\n",
    "        logp = jax.nn.log_softmax(logits, axis=-1)\n",
    "        p = jnp.exp(logp)\n",
    "        entropy = -(p * logp).sum(-1).mean()\n",
    "        train_loss = loss_weighted - config.loss.entropy_lambda * entropy\n",
    "    else:\n",
    "        train_loss = loss_weighted\n",
    "\n",
    "    # Metrics for curve comparison (do not involved in backprop)\n",
    "    # Mean CE over all positions (unweighted, for alignment with literature/old results)\n",
    "    loss_all = eval.loss_all(logits, targets)\n",
    "    loss_last = eval.cross_entropy_last_token_only(logits, targets)\n",
    "    acc_all, acc_last = eval.accuracy(logits, targets)\n",
    "    perplexity, avg_loss = eval.perplexity(logits, targets)\n",
    "    bpc = eval.bits_per_character(avg_loss)\n",
    "    avg_entropy, entropy_by_position = eval.prediction_entropy(logits)\n",
    "\n",
    "    # ECE\n",
    "    ece, calibration_data = eval.expected_calibration_error(logits, targets)\n",
    "\n",
    "    metrics = {\n",
    "        \"loss_train\": train_loss,\n",
    "        \"loss_all\": loss_all,\n",
    "        \"loss_last\": loss_last,\n",
    "        \"acc\": acc_all,\n",
    "        \"acc_last\": acc_last,\n",
    "        \"perplexity\": perplexity,\n",
    "        \"bpc\": bpc,\n",
    "        \"pred_entropy\": avg_entropy,\n",
    "        \"ece\": [ece, calibration_data],\n",
    "    }\n",
    "\n",
    "    return train_loss, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05221147",
   "metadata": {},
   "source": [
    "## Optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b720c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an update function\n",
    "def train_step(params, opt_state, x, y, tx, rng):\n",
    "    \"\"\"Single optimization step using optax optimizer.\n",
    "\n",
    "    Args:\n",
    "      params: pytree of model parameters.\n",
    "      opt_state: optax optimizer state corresponding to `params`.\n",
    "      x: (B, T) int array input tokens.\n",
    "      y: (B, T) int array target tokens.\n",
    "      tx: optax.GradientTransformation (already initialized).\n",
    "\n",
    "    Returns:\n",
    "      new_params: updated parameters after one gradient step.\n",
    "      new_opt_state: updated optimizer state.\n",
    "      metrics: dict of scalar metrics (loss, acc).\n",
    "    \"\"\"\n",
    "\n",
    "    rng, dropout_rng = jax.random.split(rng)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = model.apply(\n",
    "            {\"params\": params},\n",
    "            x,\n",
    "            deterministic=False,\n",
    "            rngs={\"dropout\": dropout_rng},\n",
    "        )\n",
    "        loss, metrics = loss_and_metrics(logits, y)\n",
    "        return loss, metrics\n",
    "\n",
    "    # compute gradients (loss is scalar, metrics is auxiliary)\n",
    "    (loss, metrics), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "\n",
    "    # optax update: compute parameter updates and new optimizer state\n",
    "    updates, new_opt_state = tx.update(grads, opt_state, params)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state, metrics\n",
    "\n",
    "\n",
    "# jit: last argument should be static because it is an object\n",
    "train_step = jax.jit(train_step, static_argnames=(\"tx\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d8e59",
   "metadata": {},
   "source": [
    "## Batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb30f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch from the training data\n",
    "def get_batch(text_int, B, T):\n",
    "    \"\"\"Create a random batch of data from text_int.\n",
    "\n",
    "    Args:\n",
    "      text_int: 1D array of token ids.\n",
    "      B: batch size (number of sequences).\n",
    "      T: sequence length (number of tokens per sequence).\n",
    "\n",
    "    Returns:\n",
    "      x: (B, T) int array input tokens.\n",
    "      y: (B, T) int array target tokens.\n",
    "    \"\"\"\n",
    "    # choose random starting indices for each sequence in the batch\n",
    "    ix = np.random.randint(0, len(text_int) - T, size=B)\n",
    "    # inputs are text from i to i+T\n",
    "    x = np.stack([text_int[i:i+T] for i in ix])\n",
    "    # targets are text from i+1 to i+T+1\n",
    "    y = np.stack([text_int[i+1:i+T+1] for i in ix])\n",
    "    return jnp.array(x, dtype=jnp.int32), jnp.array(y, dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da80db",
   "metadata": {},
   "source": [
    "## Optimizer creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate scheduler\n",
    "lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "    init_value=0.0,\n",
    "    peak_value=config.training.learning_rate,\n",
    "    warmup_steps=config.training.warmup_iters,\n",
    "    decay_steps=max(1, config.training.epochs - config.training.warmup_iters),\n",
    "    end_value=0.0,\n",
    ")\n",
    "\n",
    "# Create AdamW optimizer (Optax)\n",
    "tx = optax.chain(\n",
    "    # gradient clipping (optiaonal)\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adamw(\n",
    "        learning_rate=lr_schedule,\n",
    "        b1=0.9,\n",
    "        b2=0.95,\n",
    "        eps=1e-8,\n",
    "        weight_decay=0.1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize optimizer state for current params\n",
    "opt_state = tx.init(params)\n",
    "\n",
    "print(\"Optimizer initialized: AdamW with warmup-cosine schedule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5d7d8",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = Path(f\"{config.output.checkpoint_dir}/{config.model_name}\").resolve()\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STAGE_DIR = CKPT_DIR / 'stage'\n",
    "BEST_DIR = CKPT_DIR / 'best'\n",
    "STAGE_DIR.mkdir(exist_ok=True)\n",
    "BEST_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint directory: {CKPT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec46a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_logger = logger.Logger(config.training.epochs)\n",
    "print(f\"Logger initialized: {metrics_logger}\")\n",
    "\n",
    "time_train_history = []\n",
    "time_val_history = []\n",
    "\n",
    "checkpoints_to_save = {\n",
    "    'stage': [],\n",
    "    'best_loss_all': None,\n",
    "    'best_acc': None,\n",
    "    'best_acc_last': None,\n",
    "    'best_perplexity': None,\n",
    "}\n",
    "\n",
    "rng = jax.random.PRNGKey(config.training.seed)\n",
    "\n",
    "print(\"Training initialization complete\")\n",
    "print(f\"- Number of Epochs: {config.training.epochs:,}\")\n",
    "print(f\"- Batch size: {config.training.batch_size}\")\n",
    "print(f\"- Eval interval: {config.training.eval_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "for it in range(config.training.epochs):\n",
    "    batch = get_batch(train_text_int, config.training.batch_size, config.training.sequence_length)\n",
    "    input, target = batch[0], batch[1]\n",
    "    params_new, opt_state_new, metrics = train_step(params, opt_state, input, target, tx, rng)\n",
    "\n",
    "    # update params and opt_state\n",
    "    params = params_new\n",
    "    opt_state = opt_state_new\n",
    "\n",
    "    # step_count = get_step_count(opt_state)\n",
    "    lr = 1\n",
    "\n",
    "    metrics_logger.log_train(metrics, lr)\n",
    "\n",
    "    time_train_history.append(time.time() - time_start)\n",
    "\n",
    "    if it % config.training.eval_interval == 0 or it == config.training.epochs - 1:\n",
    "        time_since_start = time.time() - time_start\n",
    "\n",
    "        # compute loss on validation set\n",
    "        B_val, T_val = 1024, 32\n",
    "        val_batch = get_batch(val_text_int, B_val, T_val)\n",
    "        val_input, val_target = val_batch[0], val_batch[1]\n",
    "        val_logits = model.apply({\"params\": params}, val_input, deterministic=True)\n",
    "\n",
    "        # validation metrics\n",
    "        val_weighted_loss, val_metrics = loss_and_metrics(val_logits, val_target)\n",
    "\n",
    "        # record validation metrics\n",
    "        metrics_logger.log_eval(it, val_metrics)\n",
    "        time_val_history.append(time_since_start)\n",
    "\n",
    "        # print validation metrics\n",
    "        metrics_logger.print_metrics(time_since_start)\n",
    "\n",
    "        is_best_loss_all, is_best_acc, is_best_acc_last, is_best_perplexity = metrics_logger.isBest(val_metrics)\n",
    "\n",
    "        # save checkpoints\n",
    "        checkpoint_state = {\n",
    "            'params': params,\n",
    "            'opt_state': opt_state,\n",
    "            'rng': rng,\n",
    "            'step': it,\n",
    "            'val_loss': float(val_metrics['loss_all']),\n",
    "            'val_acc': float(val_metrics['acc']),\n",
    "            'val_acc_last': float(val_metrics['acc_last']),\n",
    "        }\n",
    "\n",
    "        if (it + 1) % config.training.stage_checkpoint_interval == 0 or (it + 1) == config.training.epochs:\n",
    "            checkpoints_to_save['stage'].append((it, checkpoint_state.copy()))\n",
    "            print(f\"\\t \\t Saved stage checkpoint @ {it:,}\")\n",
    "\n",
    "        if is_best_loss_all:\n",
    "            checkpoints_to_save['best_loss_all'] = (it, checkpoint_state.copy())\n",
    "            print(f\"\\t \\t Saving best loss checkpoint at iteration {it}...\")\n",
    "\n",
    "        if is_best_acc:\n",
    "            checkpoints_to_save['best_acc'] = (it, checkpoint_state.copy())\n",
    "            print(f\"\\t \\t Saving best accuracy checkpoint at iteration {it}...\")\n",
    "\n",
    "        if is_best_acc_last:\n",
    "            checkpoints_to_save['best_acc_last'] = (it, checkpoint_state.copy())\n",
    "            print(f\"\\t \\t Saving best last-character accuracy checkpoint at iteration {it}...\")\n",
    "\n",
    "        if is_best_perplexity:\n",
    "            checkpoints_to_save['best_perplexity'] = (it, checkpoint_state.copy())\n",
    "            print(f\"\\t \\t Saving best perplexity checkpoint at iteration {it}...\")\n",
    "\n",
    "total_time = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d35f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_collected_checkpoints(checkpoints_to_save, STAGE_DIR, BEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e1896",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(f\"{config.output.results_dir}/{config.model_name}\").resolve()\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results = analyze_training_performance(\n",
    "    metrics_logger=metrics_logger,\n",
    "    total_time=total_time,\n",
    "    niter=config.training.epochs,\n",
    "    n_final=10,\n",
    "    save_results=True,\n",
    "    results_path=str(results_dir / 'training_results.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01852a7",
   "metadata": {},
   "source": [
    "## Loss Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(\n",
    "    metrics_logger=metrics_logger,\n",
    "    save_path=str(results_dir / 'training_curves.pdf')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61719c",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello my fri\"\n",
    "gen_len = 1000\n",
    "temperature = 0.7\n",
    "sample = True\n",
    "seed = 4212\n",
    "sb_n_grams = 4\n",
    "sb_n_samples = 20\n",
    "\n",
    "checkpoint_types = [\n",
    "    ('best_loss_all_', 'Best Loss'),\n",
    "    ('best_acc_total_', 'Best Accuracy'),\n",
    "    ('best_acc_last_', 'Best Last-Char Accuracy'),\n",
    "    ('best_perplexity_', 'Best Perplexity'),\n",
    "    ('stage_1_', 'Mid Epoch')\n",
    "]\n",
    "\n",
    "for prefix, name in checkpoint_types:\n",
    "    print(f\"\\n{name}...\")\n",
    "    try:\n",
    "        # load checkpoint\n",
    "        checkpoint = load_checkpoint(prefix, name, BEST_DIR, STAGE_DIR)\n",
    "        params = checkpoint['params']\n",
    "\n",
    "        # test checkpoint\n",
    "        test_checkpoint(model, params, test_text_int)\n",
    "        sb = eval.self_bleu(\n",
    "            model, config, int_to_char, char_to_int, char_set, params, prompt, gen_len, temperature, sample, seed,\n",
    "            n_grams = sb_n_grams, n_samples = sb_n_samples\n",
    "        )\n",
    "\n",
    "        # generate text\n",
    "        rng = jax.random.PRNGKey(seed)\n",
    "        prompt_int = jnp.array(\n",
    "            [[char_to_int.get(c, len(char_set)) for c in prompt.lower()[:config.model.max_len]]],\n",
    "            dtype=jnp.int32\n",
    "        )\n",
    "        out_ids = generation.generate_tokens(\n",
    "            model, params, rng, prompt_int, gen_len,\n",
    "            block_size=config.model.max_len,\n",
    "            temperature=temperature,\n",
    "            sample=sample\n",
    "        )\n",
    "        generated_text = ''.join(int_to_char.get(int(x), '?') for x in list(out_ids[0]))\n",
    "        full_text = prompt + generated_text\n",
    "\n",
    "        # save to file\n",
    "        filename = prefix.replace('_', '') + '.txt'\n",
    "        output_path = results_dir / filename\n",
    "\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(f\"{name}\\n\")\n",
    "            f.write(f\"Step: {checkpoint['step']}\\n\")\n",
    "            f.write(f\"Validation Loss: {checkpoint['val_loss']:.4f}\\n\")\n",
    "            f.write(f\"Validation Acc: {100*checkpoint['val_acc']:.2f}%\\n\\n\")\n",
    "            f.write(f\"\\t \\tSelf-BLEU-{sb_n_grams}: {sb:.4f}\\n\")\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"\\tSaved to {output_path}\")\n",
    "        print(f\"\\tPreview: {full_text[:100]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\tError: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charllm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
